<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Kishan&#39;s World</title>
    <link>http://kshnsink.com/posts/</link>
    <description>Recent content in Posts on Kishan&#39;s World</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 May 2023 03:52:06 +0530</lastBuildDate><atom:link href="http://kshnsink.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Resource Mangement in Kubernetes Cluster: Understanding Resources</title>
      <link>http://kshnsink.com/posts/resource-mangement-in-kubernetes-clusterunderstanding-resources/</link>
      <pubDate>Thu, 11 May 2023 03:52:06 +0530</pubDate>
      
      <guid>http://kshnsink.com/posts/resource-mangement-in-kubernetes-clusterunderstanding-resources/</guid>
      <description>Understanding Kubernetes resources and Quality of Service classes</description>
      <content:encoded><![CDATA[<p>Kubernetes is a container orchestration platform that allows you to manage and automate the deployment, scaling and management of containerised application. In this post we will look into the resource management in Kubernetes which involves allocating resources such as CPU, memory to the containers running in a cluster</p>
<h1 id="understanding-resource">Understanding Resource</h1>
<p>At the heart of a Kubernetes cluster  is a resource abstraction called <strong>pods</strong> which groups containers together and manage their resources as a unit.  ****Each pod is assigned a certain amount of CPU and memory resources, which are used by the containers running within the pod. Pods run on a node in the cluster and the node size in terms of memory and CPU in a cluster is definite. Only certain number of pods can be run in a cluster and it is a duty of a Kubernetes cluster admin to assign the resources to the pod optimally to get the best utilization and at the same time ensuring that there’s enough room to deal with increasing load and failures.</p>
<p>Kubernetes scheduler decides where to place a pod in the cluster, basically which node has spare resource. In order to schedule pods effectively, the scheduler must know the resource requirements for each pod. This is where Kubernetes resource requests and limits kicks in</p>
<h2 id="container-resource">Container Resource</h2>
<h3 id="requests-and-limitshttpskubernetesiodocsconceptsconfigurationmanage-resources-containersrequests-and-limits"><a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits">Requests and Limits</a></h3>
<p>Kubernetes resource configuration consists of two components: <code>requests</code> and <code>limits</code>.</p>
<ul>
<li>request specifies the minimum amount of a request that a pod needs to run.</li>
<li>limit specifies the maximum amount of resource that a pod is allowed to use.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;200Mi&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;400m&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">memory</span>: <span style="color:#e6db74">&#34;400Mi&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cpu</span>: <span style="color:#e6db74">&#34;800m&#34;</span>
</span></span></code></pre></div><p>Setting resource requests and limits allows to accommodate spiky Pods in a cluster. Resource limits are a hard boundary for a pod. A pod that tries to use more than its allocated CPU limit which is a <em>compressible resource</em> will be throttled thus impacting performance and if it tries to use more than the allowed memory limit which is an incompressible resource, the pod gets terminated with OOM error. Scheduler tries to schedule the pod in any other nodes in the cluster if there’s enough memory in the node. Kubernetes allows resources to be overcommitted which means the sum of all the resource limits of containers on a cluster(node) can exceed the total resources.</p>
<p>Despite all the efforts put upfront in defining the resource requirements, what happens if the containers are using more resources than allocated. Kubernetes uses <code>Quality of Service (QoS)</code> classes to make a decision about evicting pods in resource crunch situations.</p>
<h2 id="quality-of-serviceqos">Quality of Service(QoS)</h2>
<p>Kubernetes has 3 QoS classes <em>Guaranteed</em>, <em>Burstable</em>, or <em>BestEffort</em> defined. This cannot be assigned directly by you, rather Kubernetes does it for you on the basis of resources defined in the Pod manifest.</p>
<h3 id="guaranteed">Guaranteed</h3>
<p>When containers Limits(CPU and Memory) matches requests(CPU and memory). This essentially means that control plane kills this Pod if it exceeds the specified limits.</p>
<p><img loading="lazy" src="/img/guaranteed_qos_class.jpg" alt=" "  />
</p>
<blockquote>
<p>Note: If a Container specifies its own memory limit, but does not specify a memory request, Kubernetes automatically assigns a memory request that matches the limit. Similarly, if a Container specifies its own CPU limit, but does not specify a CPU request, Kubernetes automatically assigns a CPU request that matches the limit.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl get po qos-pod-guaranteed -o yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">200m</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">400Mi</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">200m</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">400Mi</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">qosClass</span>: <span style="color:#ae81ff">Guaranteed </span>
</span></span></code></pre></div><h3 id="burstable">Burstable</h3>
<p>When containers Limits is higher than Requests. Kubernetes allows burstable pods upto their limit if capacity is available in the node. If the pod uses more resources than the request and there’s not enough resource available in the node, the pod gets terminated.</p>
<p><img loading="lazy" src="/img/burstable_qos_class.jpg" alt=" "  />
</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl get po qos-pod-burstable -o yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">limits</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">200m</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">400Mi</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">requests</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">cpu</span>: <span style="color:#ae81ff">400m</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">memory</span>: <span style="color:#ae81ff">800Mi</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">...</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">qosClass</span>: <span style="color:#ae81ff">Burstable </span>
</span></span></code></pre></div><h3 id="besteffort">BestEffort</h3>
<p>When containers doesn’t specify any resource request or limits. In this situation pods are allowed to use whatever resource is available on the node but it will be the first one to be killed when the cluster needs to make room for higher(Burstable/Guaranteed) QoS pods.</p>
<p><img loading="lazy" src="/img/besteffort_qos_class.jpg" alt=" "  />
</p>
<h2 id="what-should-you-do">What should you do?</h2>
<p>In the first instance it seems that Guaranteed is the best QoS class to set for the pods. But remember resource(memory/CPU) has some cost 💰. Let us try and understand how this can be approached. Considering we have a definite resource at hand and if we want to set request and limits equal(Guaranteed QoS class) we have to either increase requests or lower the limits. In case of increasing the resource, we might be blocking too much of resource unnecessarily and some other Pod which could have been scheduled in the node is not getting the resource. If we lower the Limit, the pod might throttle during the peak/spike hours. This seems like a similar territory when VMs are used.</p>
<blockquote>
<p><em>Scheduling of a Pod is based on requests and not limits</em></p>
</blockquote>
<p>The place where Kubernetes is different from the conventional resource allocation is when we use Burstable pods. Here, the amount of resource blocked by the pod is lower than the amount of resource pod needs during surge hours.</p>
<p>Pods with QoS class as <em>BestEffort</em> gets the <strong>lowest priority.</strong> If resource is not specified, Kubernetes scheduler will place such pods on any of the node which has available resource.</p>
<p>During the eviction, Kubelet selects the Pods to evict in order of QoS class. Pods classified as BestEffort will be first evicted followed by Burstable and finally Guaranteed.</p>
<blockquote>
<p><em>Always specify resource requests and limits. This helps Kubernetes schedule and manage the pods properly. For critical pods or stateful sets, prefer Guaranteed class and Burstable for the less critical ones</em></p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>Kubernetes Prometheus Monitoring</title>
      <link>http://kshnsink.com/posts/kubernetes-prometheus-monitoring/</link>
      <pubDate>Tue, 25 Apr 2023 01:26:36 +0530</pubDate>
      
      <guid>http://kshnsink.com/posts/kubernetes-prometheus-monitoring/</guid>
      <description>Using Prometheus to monitor kubernetes cluster</description>
      <content:encoded><![CDATA[<h2 id="monitoring-kubernetes-cluster-with-prometheus">Monitoring Kubernetes cluster with Prometheus</h2>
<p>Prometheus is a widely used open-source monitoring system that is commonly used for monitoring Kubernetes environments. In Kubernetes, Prometheus can be used to monitor various Kubernetes components such as pods, nodes, and services. Kubernetes provides an API that allows Prometheus to discover the endpoints of the different components and collect metrics from them. These metrics can include CPU usage, memory usage, network traffic, and other relevant information. Prometheus also provides a variety of built-in visualization tools such as Grafana, which can be used to visualize the collected metrics. This allows users to create dashboards that provide a high-level view of the cluster&rsquo;s health and performance.</p>
<p>There are fundamentally two things that we can monitor in kubernetes system</p>
<ul>
<li>Monitor applications running on kubernetes infrastructure</li>
<li>Monitor kubernetes cluster
<ul>
<li>control plane components such as coreDNS, apiserver, kube scheduler</li>
<li>kubelet(cAdvisor) which exposes container metrics</li>
<li>kube-state-metrics which is basically the cluster level metrics around deployments, pod etc</li>
<li>node-exporter which runs on all the nodes and exposes metrics around CPU, memory, network. Node exporter can be run on a kubernetes cluster in the following ways
<ul>
<li>manually run in each nodes in the cluster</li>
<li>use kubernetes daemonset which allows to run pod of node-exporter in all the nodes in the cluster</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Kubernetes doesn’t expose these metrics by default. For that we need to install kube state metrics container into our kubernetes environment and this container is responsible for making it available to the prometheus server.</p>
<h2 id="deploying-prometheus">Deploying Prometheus</h2>
<p>There are multiple options to deploy prometheus.</p>
<ol>
<li>Manually deploy premotheus on kubernetes. this requires manually creating all the deployments, configmaps, services secrets etc.</li>
<li>Deploy using Helm chart to deploy prometheus operator</li>
</ol>
<h2 id="operators-in-kubernetes">Operators in Kubernetes</h2>
<p>A kubernetes operator is a method of packaging, deploying and managing a kubernetes application. A Kubernetes operator is an application-specific controller that extends the functionality of the Kubernetes API to create, configure, and manage instances of complex applications on behalf of a Kubernetes user.</p>
<h2 id="prometheus-operatorhttpsgithubcomprometheus-operatorprometheus-operator"><a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus operator</a></h2>
<p>The Prometheus Operator provides Kubernetes native deployment and management of Prometheus and related monitoring components.
The Prometheus operator includes the following features:</p>
<ul>
<li><strong>Kubernetes Custom Resources</strong>: Use Kubernetes custom resources to deploy and manage Prometheus, AlertManager, and related components.</li>
<li><strong>Simplified Deployment Configuration</strong>: Configure the fundamentals of Prometheus like versions, persistence, retention policies, and replicas from a native Kubernetes resource.</li>
<li><strong>Prometheus Target Configuration</strong>: Automatically generate monitoring target configurations based on familiar Kubernetes label queries; no need to learn a Prometheus specific configuration language.</li>
</ul>
<p><a href="https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/getting-started.md">user guide</a></p>
<p>This operator comes with several resources such as AlertManager, ServiceMonitor, PodMonitor, PrometheusRule, AlertManager config</p>
<h2 id="service-monitors">Service Monitors</h2>
<p>The Prometheus operator comes with several custom resource definitions that provide a high level abstraction for deploying prometheus.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get crd
</span></span><span style="display:flex;"><span>servicemonitors.monitoring.coreos.com       2023-04-24T12:28:54Z
</span></span><span style="display:flex;"><span>prometheusrules.monitoring.coreos.com       2023-04-24T12:28:54Z
</span></span></code></pre></div><p><strong>Service monitors</strong> define a set of targets for prometheus to monitor and scrape. They allow you to avoid touching prometheus configs directly and give you a declarative kubernetes syntax to define targets</p>
<blockquote>
<p>Writing and maintaining configuration in prometheus is a pain, that’s why there’s a thing called service monitor. A service monitor tells prometheus what services in kubernetes to monitor so if you have an arbitrary deployment with some pods running behind it and you’re exposing a service to that pod you can create a service monitor that uses a label selector to select the service and then in prometheus you can label the selectors to select the service monitors that prometheus needs to consume that’ll tell prometheus what service endpoints to start scraping to collect metrics.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#ae81ff">kubectl get servicemonitors.monitoring.coreos.com prometheus-kube-prometheus-prometheus -o yaml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">monitoring.coreos.com/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ServiceMonitor</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">meta.helm.sh/release-name</span>: <span style="color:#ae81ff">prometheus</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">meta.helm.sh/release-namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">creationTimestamp</span>: <span style="color:#e6db74">&#34;2023-04-24T12:29:25Z&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">generation</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">kube-prometheus-stack-prometheus</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app.kubernetes.io/instance</span>: <span style="color:#ae81ff">prometheus</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app.kubernetes.io/managed-by</span>: <span style="color:#ae81ff">Helm</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app.kubernetes.io/part-of</span>: <span style="color:#ae81ff">kube-prometheus-stack</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app.kubernetes.io/version</span>: <span style="color:#ae81ff">45.20.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">chart</span>: <span style="color:#ae81ff">kube-prometheus-stack-45.20.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">heritage</span>: <span style="color:#ae81ff">Helm</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">release</span>: <span style="color:#ae81ff">prometheus</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">prometheus-kube-prometheus-prometheus</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resourceVersion</span>: <span style="color:#e6db74">&#34;193503&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">uid</span>: <span style="color:#ae81ff">8be1b353-047e-4b9b-ba15-d1a6517cf2cd</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">endpoints</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/metrics</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">port</span>: <span style="color:#ae81ff">http-web</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespaceSelector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchNames</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">default</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">kube-prometheus-stack-prometheus</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">release</span>: <span style="color:#ae81ff">prometheus</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">self-monitor</span>: <span style="color:#e6db74">&#34;true&#34;</span>
</span></span></code></pre></div><h2 id="installing-prometheus-with-helm-charthttpsgithubcomprometheus-communityhelm-chartstreemainchartskube-prometheus-stack"><a href="https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack">Installing Prometheus with Helm chart</a></h2>
<p><a href="https://github.com/prometheus-operator/kube-prometheus">kube-prometheus stack</a> is a collection of Kubernetes manifests, <a href="http://grafana.com/">Grafana</a>
dashboards, and <a href="https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/">Prometheus rules</a> combined with documentation and scripts to provide easy to operate end-to-end Kubernetes cluster monitoring with <a href="https://prometheus.io/">Prometheus</a> using the <a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a></p>
<ul>
<li><strong>Get Helm Repository Info</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
</span></span><span style="display:flex;"><span>helm repo update
</span></span></code></pre></div><ul>
<li><strong>Install Helm Chart</strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>helm install prometheus prometheus-community/kube-prometheus-stack
</span></span></code></pre></div><p>This helm chart creates all the prometheus resources in the cluster</p>
<p>To see what it has created, let’s get all the resources</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get all
</span></span><span style="display:flex;"><span>NAME                                                         READY   STATUS    RESTARTS      AGE
</span></span><span style="display:flex;"><span>pod/alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running   <span style="color:#ae81ff">1</span> <span style="color:#f92672">(</span>11m ago<span style="color:#f92672">)</span>   13m
</span></span><span style="display:flex;"><span>pod/prometheus-grafana-6984c5759f-2wmlz                      3/3     Running   <span style="color:#ae81ff">0</span>             14m
</span></span><span style="display:flex;"><span>pod/prometheus-kube-prometheus-operator-5f8db7f79c-j9z9t     1/1     Running   <span style="color:#ae81ff">0</span>             14m
</span></span><span style="display:flex;"><span>pod/prometheus-kube-state-metrics-7fbdd95dc4-nrj49           1/1     Running   <span style="color:#ae81ff">0</span>             14m
</span></span><span style="display:flex;"><span>pod/prometheus-prometheus-kube-prometheus-prometheus-0       2/2     Running   <span style="color:#ae81ff">0</span>             13m
</span></span><span style="display:flex;"><span>pod/prometheus-prometheus-node-exporter-5bzbv                1/1     Running   <span style="color:#ae81ff">0</span>             14m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>                      AGE
</span></span><span style="display:flex;"><span>service/alertmanager-operated                     ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   13m
</span></span><span style="display:flex;"><span>service/kubernetes                                ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP                      13d
</span></span><span style="display:flex;"><span>service/prometheus-grafana                        ClusterIP   10.96.182.45     &lt;none&gt;        80/TCP                       14m
</span></span><span style="display:flex;"><span>service/prometheus-kube-prometheus-alertmanager   ClusterIP   10.111.178.253   &lt;none&gt;        9093/TCP                     14m
</span></span><span style="display:flex;"><span>service/prometheus-kube-prometheus-operator       ClusterIP   10.107.58.215    &lt;none&gt;        443/TCP                      14m
</span></span><span style="display:flex;"><span>service/prometheus-kube-prometheus-prometheus     ClusterIP   10.100.157.20    &lt;none&gt;        9090/TCP                     14m
</span></span><span style="display:flex;"><span>service/prometheus-kube-state-metrics             ClusterIP   10.102.14.155    &lt;none&gt;        8080/TCP                     14m
</span></span><span style="display:flex;"><span>service/prometheus-operated                       ClusterIP   None             &lt;none&gt;        9090/TCP                     13m
</span></span><span style="display:flex;"><span>service/prometheus-prometheus-node-exporter       ClusterIP   10.96.1.108      &lt;none&gt;        9100/TCP                     14m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                                 DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
</span></span><span style="display:flex;"><span>daemonset.apps/prometheus-prometheus-node-exporter   <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           &lt;none&gt;          14m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                                  READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style="display:flex;"><span>deployment.apps/prometheus-grafana                    1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           14m
</span></span><span style="display:flex;"><span>deployment.apps/prometheus-kube-prometheus-operator   1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           14m
</span></span><span style="display:flex;"><span>deployment.apps/prometheus-kube-state-metrics         1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           14m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                                             DESIRED   CURRENT   READY   AGE
</span></span><span style="display:flex;"><span>replicaset.apps/prometheus-grafana-6984c5759f                    <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       14m
</span></span><span style="display:flex;"><span>replicaset.apps/prometheus-kube-prometheus-operator-5f8db7f79c   <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       14m
</span></span><span style="display:flex;"><span>replicaset.apps/prometheus-kube-state-metrics-7fbdd95dc4         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       14m
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                                                                    READY   AGE
</span></span><span style="display:flex;"><span>statefulset.apps/alertmanager-prometheus-kube-prometheus-alertmanager   1/1     13m
</span></span><span style="display:flex;"><span>statefulset.apps/prometheus-prometheus-kube-prometheus-prometheus       1/1     13m
</span></span></code></pre></div><h3 id="resources-created">Resources created</h3>
<blockquote>
<p>Let&rsquo;s understand the important resources we have created</p>
</blockquote>
<h4 id="deployments">Deployments</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get deployments
</span></span><span style="display:flex;"><span>NAME                                                  READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style="display:flex;"><span>deployment.apps/prometheus-grafana                    1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           14m
</span></span><span style="display:flex;"><span>deployment.apps/prometheus-kube-prometheus-operator   1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           14m
</span></span><span style="display:flex;"><span>deployment.apps/prometheus-kube-state-metrics         1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           14m
</span></span></code></pre></div><ul>
<li><strong>Prometheus Grafana:</strong> is a graphical UI tool that is used to visualize the data that is there in the prometheus time series database</li>
<li><strong>Kube prometheus operator</strong>: this is the operator that is going to manage the lifecycle of the prometheus instance. It handles the update of configs, restart the process upon changes in the config</li>
<li><strong>Kube state metrics</strong>: container for exposing cluster level metrics such as deployments, pods, services</li>
</ul>
<h4 id="statefulset">StatefulSet</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get statefulset
</span></span><span style="display:flex;"><span>NAME                                                                    READY   AGE
</span></span><span style="display:flex;"><span>statefulset.apps/alertmanager-prometheus-kube-prometheus-alertmanager   1/1     13m
</span></span><span style="display:flex;"><span>statefulset.apps/prometheus-prometheus-kube-prometheus-prometheus       1/1     13m
</span></span></code></pre></div><ul>
<li><strong>Prometheus server</strong>: this is a container that’s running the prometheus process</li>
<li><strong>AlertManager</strong>: alert manager instance</li>
</ul>
<h4 id="daemonset">Daemonset</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get daemonset
</span></span><span style="display:flex;"><span>NAME                                                 DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
</span></span><span style="display:flex;"><span>daemonset.apps/prometheus-prometheus-node-exporter   <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>         <span style="color:#ae81ff">1</span>       <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           &lt;none&gt;          14m
</span></span></code></pre></div><ul>
<li><strong>Node exporter</strong>: responsible for deploying a node exporter pod on every single node in the cluster and this pod is responsible for collecting host metrics such as CPU utilization, memory utilization and exposes it to prometheus server</li>
</ul>
<h2 id="connecting-to-prometheus-server">Connecting to prometheus server</h2>
<p>The prometheus service is of type clusterIP and can be accessed from within the cluster. To connect to the prometheus server from outside the cluster we can either make the service of type nodeport or load balancer or use an ingress to route traffic to the service.</p>
<p>we can also port forward the prometheus pod to access it locally</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl port-forward prometheus-prometheus-kube-prometheus-prometheus-0 <span style="color:#ae81ff">9090</span>
</span></span></code></pre></div><h2 id="prometheus-kubernetes-configurationhttpsprometheusiodocsprometheuslatestconfigurationconfigurationkubernetes_sd_config"><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config">Prometheus kubernetes configuration</a></h2>
<p>Kubernetes SD configurations allow retrieving scrape targets from <a href="https://kubernetes.io/">Kubernetes</a> REST API and always staying synchronized with the cluster state. One of the following role types can be configured to discover targets.</p>
<ul>
<li>role
<ul>
<li>service</li>
<li>node</li>
<li>pod</li>
<li>endpoints</li>
<li>endpointsslice</li>
<li>ingress</li>
</ul>
</li>
</ul>
<blockquote>
<p>The default config uses the role <code>endpoint</code> because the endpoint role discovers targets from listed endpoints of a service and thus we can basically discover pods, services, nodes and everything else using the endpoints</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kubernetes_sd_configs</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">role</span>: <span style="color:#ae81ff">endpoints</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubeconfig_file</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">follow_redirects</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">enable_http2</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">namespaces</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">own_namespace</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">names</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">default</span>
</span></span></code></pre></div><h2 id="prometheus-rules">Prometheus Rules</h2>
<p>To add rules, prometheus operator has a CRD called prometheusrule which handles registering new rules to a prometheus instance</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get prometheusrules.monitoring.coreos.com
</span></span></code></pre></div>]]></content:encoded>
    </item>
    
    <item>
      <title>Intro to Gateway API</title>
      <link>http://kshnsink.com/posts/intro-to-gateway-api/</link>
      <pubDate>Sun, 09 Apr 2023 12:22:06 +0530</pubDate>
      
      <guid>http://kshnsink.com/posts/intro-to-gateway-api/</guid>
      <description>Gateway API in Kubernetes</description>
      <content:encoded><![CDATA[<h2 id="ingress-vs-gateway-api">Ingress vs Gateway API</h2>
<h3 id="ingress-supports-the-following">Ingress supports the following</h3>
<ul>
<li>HTTP host matching</li>
<li>HTTP path matching</li>
<li>TLS termination</li>
<li>Routing to service:port</li>
<li>For many different load balancer implementations</li>
</ul>
<h3 id="gateway-adds">Gateway adds</h3>
<ul>
<li>HTTP header-based matching</li>
<li>HTTP header manipulation</li>
<li>Weighted traffic splitting</li>
<li>Traffic mirroring</li>
<li>Role-oriented resource model</li>
</ul>
<h3 id="and-has-extensibility-for">and has extensibility for</h3>
<ul>
<li>Arbitrary backend CRD references (buckets, functions, etc)</li>
<li>Routing for other protocols(gRPC)</li>
<li>Custom parameters or configuration (LB algos, custom match types, etc)</li>
</ul>
<p>Gateway controller manage the network infrastructure on behalf of Gateway resources. There are one or more Gateway classes supported by a Gateway controller. Gateways are created from the Gateway classes and they model the actual network infrastructure which processes the traffic. Gateways can model many different kinds of data planes that perform routing.</p>
<p>Then comes the route resources. Gateway and the HTTP route resources do what the ingress resource does as a single resource. This separation allows different roles to deploy and own that resource. It allows a cluster administrator to mange the Gateway and the policies attached to that Gateway, while individual development teams manage the routing to their application on their own.</p>
<p><img loading="lazy" src="/img/gateway_02.png" alt="roles"  />
</p>
<h2 id="roles-involved">Roles involved</h2>
<h3 id="infrastructure-provider">Infrastructure Provider</h3>
<p>ensures that each cluster is provisioned with a <code>GatewayClass</code> ****for external load balancers</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">GatewayClass</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">external-lb</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">controller</span>: <span style="color:#ae81ff">mygroup.io/gateway</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">parametersRef</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">k8s.mygroup.io</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">GatewayClassParams</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">external-lb</span>
</span></span></code></pre></div><h3 id="cluster-operator">Cluster Operator</h3>
<p>Creates a <code>Gateway</code> for the mygroup team when setting up the cluster</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Gateway</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mygroup-external</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">gatewayClassName</span>: <span style="color:#ae81ff">external-lb</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">listeners</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">HTTP</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">routes</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HTTPRoute</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">matchLebels</span>:
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">gateway</span>: <span style="color:#ae81ff">mygroup-external</span>
</span></span><span style="display:flex;"><span> 
</span></span></code></pre></div><h3 id="application-developer">Application Developer</h3>
<p>creates an HTTPRoute to route external traffic to the application</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HTTPRoute</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mygroup</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">gateway</span>: <span style="color:#ae81ff">mygroup-external</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">hostnames</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">mygroup.io</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">matches</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">value</span>: <span style="color:#ae81ff">/groups</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">forwardTo</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">serviceName</span>: <span style="color:#ae81ff">mygroup-groups</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>: <span style="color:#ae81ff">8080</span>
</span></span></code></pre></div><h2 id="features">Features</h2>
<h3 id="canary-rollout">Canary Rollout</h3>
<p>Application developer wants to do a canary rollout</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HTTPRoute</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">matches</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">path</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">value</span>: <span style="color:#ae81ff">/groups</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">forwardTo</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">serviceName</span>: <span style="color:#ae81ff">mygroup-groups</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">port</span>: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">90</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#f92672">serviceName</span>: <span style="color:#ae81ff">mygroup-groups-canary</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">port</span>: <span style="color:#ae81ff">8080</span>
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">weight</span>: <span style="color:#ae81ff">10</span>
</span></span></code></pre></div><h3 id="upgrade-load-balancer">Upgrade Load Balancer</h3>
<p>Cluster operator wants to upgrade to the newest kind of LB</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Gateway</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mygroup-external</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">gatewayClassName</span>: <span style="color:#ae81ff">new-external-lb</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">listeners</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">HTTP</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">routes</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">HTTPRoute</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">matchLebels</span>:
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">gateway</span>: <span style="color:#ae81ff">mygroup-external</span>
</span></span></code></pre></div><h3 id="update-infrastructure-provider">Update Infrastructure Provider</h3>
<p>Infrastructure provider wants to provision on a new provider</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">GatewayClass</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">external-lb</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">controller</span>: <span style="color:#ae81ff">new-vendor.io/gateway</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">parametersRef</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">group</span>: <span style="color:#ae81ff">k8s.mygroup.io</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">GatewayClassParams</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">external-lb</span>
</span></span></code></pre></div>]]></content:encoded>
    </item>
    
    <item>
      <title>Postgres Performance Tuning Manual: Indexes</title>
      <link>http://kshnsink.com/posts/postgres-performance-tuning-manualindexes/</link>
      <pubDate>Sun, 26 Mar 2023 02:09:41 +0530</pubDate>
      
      <guid>http://kshnsink.com/posts/postgres-performance-tuning-manualindexes/</guid>
      <description>How to modify and improve query times in Postgres with the help of indexes.</description>
      <content:encoded><![CDATA[<p>In this post, we look at how to overcome slow queries by analysing them with <code>Explain</code> and <code>Analyze</code>, and using indexes to modify and enhance the query timings.</p>
<p>Postgres supports different kinds of indexing on the table for
querying faster.</p>
<h2 id="multiple-columnindexes">Multiple column indexes</h2>
<p>A <a href="https://www.postgresql.org/docs/9.6/indexes-multicolumn.html">multi-column B-Tree index</a> can be used with query conditions that involve any subset of the index&rsquo;s columns. This index is most efficient when there are constraints on the leading (leftmost) columns. The exact rule is that equality constraints on leading columns, plus any inequality constraints on the first column that does not have an equality constraint, will be used to limit the portion of the index that is scanned.</p>
<h3 id="cover-index">Cover-Index</h3>
<p>An index containing all the columns needed for a query, which is there in the select statement.</p>
<h3 id="unique-index">Unique Index</h3>
<p>A unique index is an index used to enforce uniqueness of a column&rsquo;s value or the uniqueness of a combined value of more than one column.</p>
<blockquote>
<p>One of the most misunderstood concepts around indexing is to understand where to use a primary key, unique constraint, or unique index. Let&rsquo;s understand this using a problem:</p>
</blockquote>
<h4 id="problem-statement">Problem statement</h4>
<p>We require maximum performance with no duplicate data. Which is the better approach? Primary key, unique constraint or unique index?</p>
<p><img loading="lazy" src="/img/postgres-index-thinking.jpeg" alt=" "  />
</p>
<h4 id="solution">Solution</h4>
<blockquote>
<p><em>Note: Multiple null values are not equal, so they are not considered as a duplicate record.</em></p>
</blockquote>
<ul>
<li>Postgres automatically creates a <a href="https://www.postgresql.org/docs/9.4/indexes-unique.html">unique index</a> in the table when a primary key and unique constraint is defined in the table. Creating unique constraint then would be redundant, and unnecessarily creating indexes degrades the performance of Postgres. According to suggestions by the Postgres product team, create a unique constraint on the table and then there is no need to create a unique index on those columns.</li>
<li>Postgres creates an index for the defined primary key itself</li>
<li>When we create a unique constraint, Postgres automatically creates an index behind the scene.</li>
</ul>
<p>However, there are cases where even indexing can&rsquo;t improve performance. One such case is when we do case-insensitive searches. Let&rsquo;s understand the difference between the query cost in case of <em>case sensitive</em> and <em>case insensitive</em> search in our scheme table. Given we have an index on the column <code>scheme_name</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">ANALYSE</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes <span style="color:#66d9ef">where</span> scheme_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;weekend_scheme&#39;</span> 
</span></span></code></pre></div><blockquote>
<p>QUERY PLAN | Index scan using idx_scheme_name on schemes
(cost=0.28..8.29 rows=1 width=384)
Planning Time: 0.155 ms
Execution Time: 0.063ms</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">ANALYSE</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes <span style="color:#66d9ef">where</span> <span style="color:#66d9ef">lower</span>(scheme_name) <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;weekend_scheme&#39;</span> 
</span></span></code></pre></div><blockquote>
<p>QUERY PLAN | Seq Scan on schemes (cost=0.00..69.00 rows=5 width=384)
Filter: (lower((scheme_name) :: text) = &lsquo;weekend_scheme&rsquo; :: text)
Rows removed by filter: 999
Planning Time: 0.119 ms
Execution Time: 0.721ms</p>
</blockquote>
<p>Even though we have an index created at <code>scheme_name</code>, the function <code>lower</code> degrades the performance as it does an additional effort of converting all the values of <code>scheme_table</code> to lower case.</p>
<p>Cases when an index is not used (although it is defined).</p>
<ul>
<li>LIKE <code>'%scheme'</code> will never use an index, but LIKE <code>'scheme%'</code> can possibly use the index.</li>
<li>The upper/lower case function used in <code>where</code> clause.</li>
</ul>
<p>So whenever we want to use a function in our where clause, we could create the index in the following way to optimise the query.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">INDEX</span> idx_scheme_name <span style="color:#66d9ef">ON</span> schemes (<span style="color:#66d9ef">lower</span>(scheme_name)) 
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">ANALYSE</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes <span style="color:#66d9ef">where</span> <span style="color:#66d9ef">lower</span>(scheme_name) <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;weekend_scheme&#39;</span>
</span></span></code></pre></div><blockquote>
<p>QUERY PLAN | Bitmap heap scan on schemes ((cost=4.32..19.83 rows=5 width=384))
Recheck cond: (lower ((scheme_name) :: text) = &lsquo;weekend_scheme&rsquo; :: text)
Heap Blocks: exact=1
Bitmap scan on schemes ((cost=0.00..4.32 rows=5 width=0))
Index cond: (lower ((scheme_name) :: text) = &lsquo;weekend_scheme&rsquo; :: text)
Planning Time: 1.784 ms
Execution Time: 0.079 ms</p>
</blockquote>
<h3 id="partial-index">Partial Index</h3>
<p>Postgres supports an index over a subset of the rows of a table (known as a partial index). It&rsquo;s often the best way to index our data if we want to repeatedly analyse rows that match a given <code>WHERE</code> clause. Let us see how we can enhance the performance of Postgres using partial indexing.</p>
<h4 id="problem-statement-1">Problem statement</h4>
<p>We want to return all the schemes which are supposed to run before 11:00 am.</p>
<h4 id="solution-1">Solution</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">ANALYSE</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes <span style="color:#66d9ef">WHERE</span> start_time <span style="color:#f92672">&lt;</span> <span style="color:#e6db74">&#39;10:00:00&#39;</span>
</span></span></code></pre></div><blockquote>
<p>QUERYEXPLAIN ANALYSE SELECT * FROM schemes where lower(scheme_name) = &lsquo;weekend_scheme&rsquo; PLAN | Seq Scan on schemes (cost=0.00..66.50 rows=9 width=23)
Filter: (start_time &lt; &lsquo;10:00:00&rsquo;)
Rows removed by filter: 991
Planning Time: 0.082 ms
Execution Time: 0.226 ms</p>
</blockquote>
<p>We can create an index on <code>start_time</code> column but assuming we have a huge database, this may not be optimal for insert, update and delete. So we create an index with a condition. This kind of indexing is used when we know what we need from our select queries. Say we do a heavy read on all the schemes which are started before 10:00:00 and not much when started later.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">CREATE</span> <span style="color:#66d9ef">INDEX</span> idx_scheme_name <span style="color:#66d9ef">ON</span> schemes start_time <span style="color:#66d9ef">WHERE</span> start_time <span style="color:#f92672">&lt;</span> <span style="color:#e6db74">&#39;11:00:00&#39;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">ANALYSE</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes <span style="color:#66d9ef">WHERE</span> start_time <span style="color:#f92672">&lt;</span> <span style="color:#e6db74">&#39;10:00:00&#39;</span>
</span></span></code></pre></div><blockquote>
<p>QUERY PLAN | Bitmap heap scan on schemes ((cost=4.21..29.30 rows=9 width=23))
Recheck cond: (start_time &lt; &lsquo;10:00:00&rsquo;)
Heap Blocks: exact=8
Bitmap index scan on schemes ((cost=0.00..4.21 rows=9 width=0)
Index cond: (start_time &lt; &lsquo;10:00:00&rsquo;)
Planning Time: 1.729 ms
Execution Time: 0.075 ms</p>
</blockquote>
<p>This reduces the execution time from 0.226to 0.075.
Let&rsquo;s validate that we have not indexed all the schemes where start_time is after 11:00 AM.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">ANALYSE</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes <span style="color:#66d9ef">WHERE</span> start_time <span style="color:#f92672">&gt;</span><span style="color:#e6db74">&#39;12:00:00&#39;</span>
</span></span></code></pre></div><blockquote>
<p>QUERY PLAN | Seq Scan on schemes (cost=0.00..66.50 rows=6 width=23)
Filter: (start_time &lt; &lsquo;12:00:00&rsquo;)
Rows removed by filter: 993
Planning Time: 0.101 ms
Execution Time: 0.228ms</p>
</blockquote>
<p>This proves that partial data from schemes table is indexed and the rest of the data is not indexed. Our index size is very small and easy to maintain, helping in the maintaining task of reindexing.</p>
<h2 id="query-plan-onjoins">Query plan on JOINS</h2>
<p>The optimizer needs to pick the correct join algorithm when there are multiple tables to be joined in the select statement. Postgres uses 3 different kinds of join algorithm based on the type of join we are using.</p>
<p><strong>Nested Loop</strong>: Here, the planner can use either sequential scan or index scan for each of the elements in the first table. The planner uses a sequential scan when the second table is small. The basic logic of choosing between a sequential scan and index scan applies here too.
<strong>Hash Join</strong>: In this algorithm, the planner creates a hash table of the smaller table on the join key. The larger table is then scanned, searching the hash table for the rows which meet the join condition. This requires a lot of memory to store the hash table in the first place.
<strong>Merge Join</strong>: This is similar to merge sort algorithm. Here the planner sorts both the tables to be joined on the join attribute. The tables are then scanned in parallel to find the matching values.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">SELECT</span> schemes.rules <span style="color:#66d9ef">FROM</span> scheme_rules <span style="color:#66d9ef">JOIN</span> schemes <span style="color:#66d9ef">ON</span> (scheme_rules.scheme_id <span style="color:#f92672">=</span> schemes.id ) <span style="color:#66d9ef">where</span> scheme_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;weekend_scheme&#39;</span>;
</span></span></code></pre></div><h2 id="downsides-of-indexes-in-production-environments">Downsides of indexes in production environments</h2>
<h3 id="finding-unusedindexes">Finding unused indexes</h3>
<p>In a large production environment, finding unused indexes is advisable, because indexes eat memory. <a href="https://wiki.postgresql.org/wiki/Index_Maintenance">Postgres wiki page</a> details how we can find index summary, duplicate indexes, and index size.</p>
<h3 id="createdrop-index-vs-createdrop-index-concurrently">CREATE/DROP index vs CREATE/DROP index concurrently</h3>
<p>Creating and dropping an index in a large database can take hours or even days and the <code>CREATE INDEX</code> command blocks all the writes on a table (it doesn&rsquo;t block the reads, but this is still not ideal).</p>
<p>However, an index created concurrently with <code>CREATE INDEX</code> CONCURRENT will not acquire locks against writes. When creating index concurrently, Postgres first scans the table to build indexes and runs the index once again for the things to be added since the first pass.</p>
<p>Creating an index concurrently also has a downside though. If something goes wrong during the process, it does not roll back, and leaves an invalid index behind. Invalid indexes can be found using the following query.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> pg_class, pg_index <span style="color:#66d9ef">WHERE</span> pg_index.indisvalid <span style="color:#f92672">=</span> <span style="color:#66d9ef">false</span> <span style="color:#66d9ef">AND</span> pg_index.indexrelid <span style="color:#f92672">=</span> pg_class.oid;
</span></span></code></pre></div><h3 id="rebuilding-indexes">Rebuilding indexes</h3>
<p><a href="https://www.postgresql.org/docs/current/sql-reindex.html">REINDEX</a> rebuilds an index using the data stored in the index table, replacing the old copy of the index. If we suspect corruption of an index on a table, we can simply rebuild that index, or all indexes on the table, using <code>REINDEX INDEX</code> or <code>REINDEX TABLE</code></p>
<p>REINDEX is similar to a drop and recreate of the index in that the index contents are rebuilt from scratch. However, locking considerations are rather different. REINDEX locks out writes but not reads of the index&rsquo;s parent table. It also takes an exclusive lock on the specific index being processed, which will block reads that attempt to use that index.</p>
<blockquote>
<p>Another option is to drop index concurrently and create again concurrently.</p>
</blockquote>
<h2 id="conclusion">Conclusion</h2>
<p>This post aimed to provide an overview of how Postgres queries the database. By understanding query plans better and carefully taking measures (mostly through indexes), we can get the best performance out of the Postgres database.</p>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://www.postgresql.org/docs/8.1/index-locking.html">Index locking consideration</a></li>
<li><a href="https://www.postgresql.org/docs/8.4/locking-indexes.html">Locking indexes</a></li>
<li><a href="https://www.postgresql.org/docs/current/routine-reindex.html">Routine reindexing</a></li>
<li><a href="https://www.postgresql.org/docs/9.3/indexes-examine.html">Examining index usage</a></li>
<li><a href="https://www.postgresql.org/docs/9.3/monitoring-stats.html">Monitoring stats</a></li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>Postgres Performance Tuning Manual: Query Plans</title>
      <link>http://kshnsink.com/posts/postgres-performance-tuning-manualquery-plans/</link>
      <pubDate>Sun, 26 Mar 2023 00:11:32 +0530</pubDate>
      
      <guid>http://kshnsink.com/posts/postgres-performance-tuning-manualquery-plans/</guid>
      <description>Is Postgres slowing down on you? Here&amp;#39;s how to identify areas of improvement using query plans</description>
      <content:encoded><![CDATA[<p>Postgres is one of the most widely used open source databases in the world. At GOJEK, a lot of our products depend on Postgres as well. A lot of major companies use Postgres as their main database however when you&rsquo;re building and operating at scale, the volume of data passing through the pipelines can slow down the most efficient systems.</p>
<p>To optimise things in order to enhace performace, we can target the brain of the database whhich is <em>optimizer</em>. Optimizer interprets queries and determines the fastest method of execution. A single query optimization technique can increase database performance drastically.</p>
<p><img loading="lazy" src="/img/postgres-query-lifecycle.png" alt="postgres query lifecycle"  />
</p>
<p>This post outlines how to analyse Postgres performance using tools such as EXPLAIN and ANALYZE (which Postgres provides).</p>
<h2 id="meet-explain-analyze">Meet EXPLAIN &amp; ANALYZE</h2>
<p><code>EXPLAIN</code> gives an exact breakdown of a query. The execution plan is based on the statistics about the table, and it identifies the most efficient path to the data. This takes different database paradigms (such as indexes) into consideration. <code>EXPLAIN</code> only guesses a plan that it thinks it will execute.
This is where <code>ANALYZE</code> comes into the picture. <code>ANALYZE</code> basically runs a query to find the processing time to execute a query.</p>
<p>To quickly summarise, <code>EXPLAIN</code> and <code>ANALYZE</code> commands help improve database performance in Postgres by:</p>
<blockquote>
<p>a. <em>Displaying the execution plan that the PostgreSQL planner generates for the supplied statement.</em></p>
<p>b. <em>Actually running the command to show the run time.</em></p>
</blockquote>
<h2 id="finding-the-framework">Finding the framework</h2>
<p>Let&rsquo;s consider we have a table named <code>schemes</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes;
</span></span></code></pre></div><blockquote>
<p><em>QUERY PLAN | Seq Scan on schemes (cost=0.00..64 rows=328 width=479)</em></p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> pg_class <span style="color:#66d9ef">where</span> relname <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;schemes&#39;</span>;
</span></span></code></pre></div><p><code>pg_class</code> has the metadata about the tables.</p>
<p>Cost in the query plan is calculated using the following formula</p>
<blockquote>
<p><em>COST = (disk read pages x seq_page_cost) + (rows scanned x cpu_tuple_cost).</em></p>
</blockquote>
<ul>
<li>Disk read pages and rows scanned are the properties of <code>pg_class</code>.</li>
<li>Seq page cost is the estimated cost of disk read fetch.</li>
<li>Cpu tuple cost is the estimated cost of processing each row.
eg., COST (54 x 1.0) + (1000 x .01) = 64</li>
</ul>
<p>Let&rsquo;s see how the query plan changes when we apply filters in the select statement.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">FROM</span> schemes <span style="color:#66d9ef">WHERE</span> status <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;active&#39;</span>;
</span></span></code></pre></div><blockquote>
<p><em>QUERY PLAN | Seq Scan on schemes (cost=0.00..66.50 rows=960 width=384) Filter: ((status)::text = &lsquo;active&rsquo;::text)</em></p>
</blockquote>
<p>The estimated cost here is higher than the previous query, this is because Postgres is performing a seq scan over 1000 rows first and then filtering out the rows based on the <code>WHERE</code> clause.</p>
<h2 id="planner-cost-constants">Planner cost constants</h2>
<p>The cost variables described in this section are measured on an arbitrary scale. Only their relative values matter, hence scaling them all up or down by the same factor will result in no change in the planner&rsquo;s choices. By default, these cost variables are based on the cost of sequential page fetches; that is, seq_page_cost is conventionally set to 1.0 and the other cost variables are set with reference to that. But you can use a different scale if you prefer, such as actual execution times in milliseconds on a particular machine.</p>
<p>Unfortunately, there is no well-defined method for determining ideal values for the cost variables. They are best treated as averages over the entire mix of queries that a particular installation will receive. This means that changing them on the basis of just a few experiments is very risky. <a href="https://www.postgresql.org/docs/current/runtime-config-query.html#RUNTIME-CONFIG-QUERY-CONSTANTS">Refer planner cost constants</a>].</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">EXPLAIN</span> <span style="color:#66d9ef">SELECT</span> schemes.rules <span style="color:#66d9ef">FROM</span> scheme_rules <span style="color:#66d9ef">JOIN</span> schemes <span style="color:#66d9ef">ON</span> (scheme_rules.scheme_id <span style="color:#f92672">=</span> schemes.id ) <span style="color:#66d9ef">where</span> scheme_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;weekend_scheme&#39;</span>;
</span></span></code></pre></div><p>The query planner sometimes decides to use a two-step plan. The reason for using two-plan node is the first plan sorts the row locations identified by the index into physical order before reading them, and the other plan actually fetches those rows from the table.</p>
<h2 id="down-to-the-nuts-andbolts">Down to the nuts and bolts</h2>
<p>The first plan which does the sorting is called Bitmap scan.</p>
<p>Most common occurring matches are scanned using the <code>seq scan</code> and the least common matches are scanned using <code>index scan</code>, anything in between is scanned using <code>bitmap heap scan</code> followed by an <code>index scan</code>. One of the reasons for this is that the random I/O is very slow as compared to sequential I/O. This is all driven by analysing statistics.</p>
<h3 id="bitmap-heap-scan">Bitmap heap scan</h3>
<p>A <a href="https://www.postgresql.org/docs/8.1/performance-tips.html">bitmap heap scan</a> is like a seq scan - the difference being, rather than visiting every disk page, it scans ANDs and ORs of the applicable index together and only visits the disk pages it needs to visit. This is different from index scan where the index is visited row by row in order, which results in disk pages being visited multiple times. A bitmap scan will sequentially open a short list of disk pages and grab every applicable row in each one.</p>
<h3 id="sequential-scan-vs-index-scan">Sequential scan vs index scan</h3>
<p>There are cases where a sequential scan is faster than an index scan. When reading data from a disk, a sequential method is usually faster than reading in random order. This is because an index scan requires several I/O for each row which includes looking up a row in the index, and based on that, looking up and retrieving the row from memory(heap). On the other hand, a sequential scan requires a single I/O operation to retrieve more than one block containing multiple rows.</p>
<h2 id="query-plan-onjoins">Query plan on JOINS</h2>
<p>The optimizer needs to pick the correct join algorithm when there are multiple tables to be joined in the select statement. Postgres uses three different kinds of join algorithms based on the type of join we are using.</p>
<blockquote>
<p><em>Let&rsquo;s dive in</em></p>
</blockquote>
<p><strong>Nested Loop</strong>: Here the planner can use either a sequential scan or index scan for each of the elements in the first table. The planner uses a sequential scan when the second table is small. The basic logic of choosing between a sequential scan and index scan applies here too.
<strong>Hash Join</strong>: In this algorithm, the planner creates a hash table of the smaller table on the join key. The larger table is then scanned, searching the hash table for the rows which meet the join condition. This requires a lot of memory to store the hash table in the first place.
<strong>Merge Join</strong>: This is similar to merge sort algorithm. Here the planner sorts both the tables to be joined on the join attribute. The tables are then scanned in parallel to find the matching values.</p>
<blockquote>
<p>Further reading on how we can use Explain/Analyze with join statements <a href="https://www.postgresql.org/docs/11/using-explain.html#USING-EXPLAIN-ANALYZE">here</a></p>
</blockquote>
<p>Postgres performance tuning is a complicated task. The complexity comes in identifying the appropriate &rsquo;tunable&rsquo; from the many tools that Postgres provides. As you might have now guessed, there is no silver bullet to solving performance issues in Postgres - it&rsquo;s the use case that dictates the tuning requirements. 😅</p>
<p>Hope this helped. Keep following the blog for more updates! 🙂</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Extend CIDR</title>
      <link>http://kshnsink.com/posts/extend-cidr/</link>
      <pubDate>Thu, 23 Mar 2023 01:17:57 +0530</pubDate>
      
      <guid>http://kshnsink.com/posts/extend-cidr/</guid>
      <description>Guide to extend CIDR Range in the existing GKE cluster</description>
      <content:encoded><![CDATA[<p>A <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/alias-ips">VPC native cluster</a> uses three unique subnet ranges to allocate IPs to Nodes, Pods and Services.</p>
<p>Primary subnet IP address is used for Nodes. Node IP provides connectivity from control components like kube-proxy and kubelet to the Kubernetes API server. Node IP is the node’s connection to the rest of the cluster.</p>
<p>Secondary subnet IP address is used for Pods. Pod IP addresses are natively routable within the cluster’s VPC network and other VPC networks connected to it by VPC Network Peering. By default GKE allocates /24 alias ie., 256 alias IP addresses for 110 pods for each of the nodes.</p>
<p>Another Secondary subnet IP address is used for services. Each Service has an IP address, called the ClusterIP, assigned from the cluster’s VPC network.</p>
<p>In a VPC native cluster, these addresses are reserved before the creation of cluster to eliminate conflict and overlapping of IPs.</p>
<p>What happens when the secondary IP range exhausts?</p>
<p>Once the secondary IP address exhausts no Pods can be scheduled. The secondary Pod IP range cannot be changed once created. There is a provision to allocate a separate IP range to create separate node pools in the cluster. These two IP ranges are going to be discontigous and there are some caveats which needs to be taken care of.</p>
<p>If you use ip-masq-agent configured with the nonMasqueradeCIDRs parameter, you must update the nonMasqueradeCIDRs to include all Pod CIDR ranges.</p>
<p>If you use NetworkPolicy configured with ipBlock to specify traffic, you must update the cidr value to include all Pod CIDR ranges.</p>
<p>The other approach is to create a bigger CIDR range node pool and move workloads from the existing node pool to the newly created one. Steps for the same:</p>
<ol>
<li>
<p>Mark the nodes in the existing node pool to be non schedulable by using the kubernetes cordon command</p>
<p><code>kubectl cordon &lt;node-name&gt;</code></p>
</li>
<li>
<p>Redeploy the application and verify if the nodes are scheduling in the nodes of new node pool</p>
</li>
<li>
<p>Once verified, redeploy and move all the workloads in the new node pool.</p>
</li>
<li>
<p>Clean up and delete the old node pool.</p>
</li>
</ol>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
